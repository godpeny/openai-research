{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-06T13:57:55.714465Z",
     "start_time": "2023-08-06T13:57:55.706073Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" import \"\"\"\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import openai\n",
    "\n",
    "from langchain import OpenAI, LLMChain, PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\"\"\" set OpenAI API key \"\"\"\n",
    "load_dotenv(dotenv_path=\"../../.env\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = OpenAI(openai_api_key=openai.api_key, temperature=0.9)\n",
    "chat = ChatOpenAI(openai_api_key=openai.api_key, temperature=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-06T13:52:19.562207Z",
     "start_time": "2023-08-06T13:52:19.555362Z"
    }
   },
   "id": "38ea5c0324813853"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\"\"\" Run LLM Chain \"\"\"\n",
    "prompt_template = \"What is a good name for a company that makes {product}?\"\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=PromptTemplate.from_template(prompt_template)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-06T13:52:20.293473Z",
     "start_time": "2023-08-06T13:52:20.287929Z"
    }
   },
   "id": "4a89d47483938f02"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "{'product': 'colorful socks', 'text': '\\n\\nKaleidoscope Socks'}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain(\"colorful socks\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-06T13:52:22.301424Z",
     "start_time": "2023-08-06T13:52:21.310347Z"
    }
   },
   "id": "f0827c88fbdf74bb"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'text': '\\n\\nCozySteps Socks.'},\n {'text': '\\n\\nCyberCraft Systems.'},\n {'text': '\\n\\nFootwear Factory.'}]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Additional ways of running LLM Chain \"\"\"\n",
    "input_list = [\n",
    "    {\"product\": \"socks\"},\n",
    "    {\"product\": \"computer\"},\n",
    "    {\"product\": \"shoes\"}\n",
    "]\n",
    "\n",
    "llm_chain.apply(input_list) # \"apply\" allows you run the chain against a list of inputs:"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-06T13:53:33.845399Z",
     "start_time": "2023-08-06T13:53:33.119585Z"
    }
   },
   "id": "fb201e620d428811"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "LLMResult(generations=[[Generation(text='\\n\\nSock It Up.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nCyber-Tech Solutions.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nFootworks Shoes.', generation_info={'finish_reason': 'stop', 'logprobs': None})]], llm_output={'token_usage': {'total_tokens': 57, 'prompt_tokens': 36, 'completion_tokens': 21}, 'model_name': 'text-davinci-003'}, run=[RunInfo(run_id=UUID('5674e3c9-7915-436a-ab34-f2b01d4cf23e')), RunInfo(run_id=UUID('99ed5bce-3045-48b8-b73b-ab040a78e8ff')), RunInfo(run_id=UUID('a124b09d-5ab2-4e85-9b46-7751651a752d'))])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.generate(input_list) # \"generate\" is similar to apply, except it return an LLMResult instead of string."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-06T13:53:54.431195Z",
     "start_time": "2023-08-06T13:53:53.437467Z"
    }
   },
   "id": "b974315ca2000141"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Single input example\n",
    "# predict is similar to run method except that the input keys are specified as keyword arguments instead of a Python dict.\n",
    "llm_chain.predict(product=\"colorful socks\") "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21014dfabd8aac0d"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n\\nQ: What did the duck say when his friend died?\\nA: Quack, quack, goodbye.'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiple inputs example\n",
    "template = \"\"\"Tell me a {adjective} joke about {subject}.\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"adjective\", \"subject\"])\n",
    "llm_chain = LLMChain(prompt=prompt, llm=OpenAI(temperature=0))\n",
    "\n",
    "llm_chain.predict(adjective=\"sad\", subject=\"ducks\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-06T13:56:07.145511Z",
     "start_time": "2023-08-06T13:56:05.755841Z"
    }
   },
   "id": "284e6d7914469b01"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "\"\"\" Parsing the output \"\"\"\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "template = \"\"\"List all the colors in a rainbow\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[], output_parser=output_parser)\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-06T13:58:17.310560Z",
     "start_time": "2023-08-06T13:58:17.295609Z"
    }
   },
   "id": "1afb140f57ade5d"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n\\nRed, Orange, Yellow, Green, Blue, Indigo, Violet'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-06T13:58:37.553008Z",
     "start_time": "2023-08-06T13:58:36.786915Z"
    }
   },
   "id": "49b5fb96bae35aa3"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/godpeny/Code/venv/openai-research/lib/python3.11/site-packages/langchain/chains/llm.py:275: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "['Red', 'orange', 'yellow', 'green', 'blue', 'indigo', 'violet']"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict_and_parse()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-06T13:58:45.179670Z",
     "start_time": "2023-08-06T13:58:44.299969Z"
    }
   },
   "id": "defc7fa11e9c950c"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d3dcc61a59b7e50c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
